version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"

  spark:
    image: bitnami/spark:latest
    environment:
      SPARK_MODE: master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./processing:/opt/spark-app
    command: ["spark-shell"]

  hbase:
    image: harisekhon/hbase
    ports:
      - "16010:16010"
      - "2181:2181"
      - "8080:8080"
    environment:
      HBASE_HEAPSIZE: 512m
      ZK_HEAPSIZE: 512m
    volumes:
      - ./hbase:/data

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - ./mongodb:/data/db

  airflow:
    image: apache/airflow:2.5.1
    ports:
      - "8081:8080"
    volumes:
      - ./airflow:/usr/local/airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__DAGS_FOLDER: /usr/local/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
